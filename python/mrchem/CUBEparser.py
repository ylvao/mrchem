
#
# MRChem, a numerical real-space code for molecular electronic structure
# calculations within the self-consistent field (SCF) approximations of quantum
# chemistry (Hartree-Fock and Density Functional Theory).
# Copyright (C) 2022 Stig Rune Jensen, Luca Frediani, Peter Wind and contributors.
#
# This file is part of MRChem.
#
# MRChem is free software: you can redistribute it and/or modify
# it under the terms of the GNU Lesser General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# MRChem is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU Lesser General Public License for more details.
#
# You should have received a copy of the GNU Lesser General Public License
# along with MRChem.  If not, see <https://www.gnu.org/licenses/>.
#
# For information on the complete list of contributors to MRChem, see:
# <https://mrchem.readthedocs.io/>
#
from .input_parser.plumbing import pyparsing as pp
import os
from json import dump

BOHR_2_METER = 5.29177210903e-11
"""Conversion from atomic units of length (Bohr) to meter (CODATA 2018)"""
ANGSTROM_2_BOHR = 1e-10 / BOHR_2_METER
#ANGSTROM_2_BOHR = 1.889725989
"""Conversion factor from Angstrom to Bohr"""

def write_cube_dict(file_dict, world_unit):
    all_path_list = []
    all_path_list.append(sort_paths(file_dict["guess_cube_p"]))
    all_path_list.append(sort_paths(file_dict["guess_cube_a"]))
    all_path_list.append(sort_paths(file_dict["guess_cube_b"]))
    all_cube_list = []
    for path_list in all_path_list:
        cube_list = []
        if (len(path_list) != 0):
            for path in path_list:
                cube_list.append(parse_cube_file(path, world_unit))
        all_cube_list.append(cube_list)

    vector_dir = file_dict["cube_vectors"]

    for index, x_list in enumerate(all_cube_list):
        sorted_list = sorted(x_list, key=lambda d: d["ORB_IDS"])
        all_cube_list[index] = sorted_list

    if (not os.path.isdir(vector_dir)) :
        os.mkdir(vector_dir)

    with open(f"{vector_dir}CUBE_p_vector.json", "w") as fd:
        dump(all_cube_list[0], fd, indent=2)

    with open(f"{vector_dir}CUBE_a_vector.json", "w") as fd:
        dump(all_cube_list[1], fd, indent=2)

    with open(f"{vector_dir}CUBE_b_vector.json", "w") as fd:
        dump(all_cube_list[2], fd, indent=2)


def sort_paths(path):
    path_l = []
    dir_path = "/".join(path.split("/")[:-1])
    directory = os.fsencode(dir_path)
    if (os.path.isdir(dir_path)):
        for file in os.listdir(directory):
            filename = os.fsdecode(file)
            if ((filename.startswith(path.split("/")[-1])) and (filename.endswith(".cube"))):
                path_l.append(dir_path+"/"+filename)
    return path_l

#TODO do a sanity check on the naming of the files

def parse_cube_file(cube_path, world_unit):

    """
    Pyparsing CUBE file
    Authors: Roberto Di Remigio & Gabriel Gerez

    Parses a CUBE file following the standard outlined in https://h5cube-spec.readthedocs.io/en/latest/cubeformat.html.
    There are two optional values in this standard, giving a set of 4 different ways of writing a CUBE file.

    Parameters
    ----------
    cube_path: path to Cube file to be parsed

    Returns
    -------
    a dictionary with information about which path the CUBE file was parsed from, the header of the CUBE file
    and vectors detailing the individual function values for each function plotted.
    """

    # non-zero unsigned integer
    nonzero_uint_t = pp.Word("123456789", pp.nums).setParseAction(pp.pyparsing_common.convertToInteger)
    # non-zero signed integer
    nonzero_int_t = pp.Word("+-123456789", pp.nums).setParseAction(lambda t: abs(int(t[0])))
    # floating point numbers, can be in scientific notation
    float_t = pp.pyparsing_common.sci_real

    # NVAL token
    nval_t = pp.Optional(~pp.LineEnd() + nonzero_uint_t, default=1)("NVAL")

    # Cartesian coordinates
    # it could be alternatively defined as: coords = pp.Group(float_t("x") + float_t("y") + float_t("z"))
    coords = pp.Group(float_t * 3)

    # row with molecular geometry
    geom_field_t = pp.Group(nonzero_uint_t("ATOMIC_NUMBER") + float_t("CHARGE") + coords("POSITION"))

    # specification of cube axes
    def axis_spec_t(d):
        return pp.Group(nonzero_uint_t("NVOXELS") + coords("VECTOR"))(f"{d.upper()}AXIS")

    before_t = pp.Group(float_t * 3)("ORIGIN") + nval_t + axis_spec_t("X") + axis_spec_t("Y") + axis_spec_t("Z")
    # the parse action flattens the list
    after_t = pp.Optional(pp.countedArray(pp.pyparsing_common.integer))("DSET_IDS").setParseAction(lambda t: t[0] if len(t) != 0 else t)

    # The molecular geometry is a variable-length list of `geom_field_t` tokens.
    # We use a modified implementation of `pyparsing`'s `countedArray` to define
    # the token for thte whole cubefile preamble, with:

    #- `before_t`: the tokens to be matched _before_ the molecular geometry:
    #  `NATOMS`, `ORIGIN`, `NVAL` (defaults to 1 if absent), and the cube axes (`XAXIS`, `YAXIS`, `ZAXIS`)
    #- `after_t`: the tokens to be matched _after_ the molecular geometry: `DSET_IDS`, if present.

    def preamble_t(pre, post):
        expr = pp.Forward()

        def count(s, l, t):
            n = t[0]
            expr << (geom_field_t * n)("GEOM")
            return n

        natoms_t = nonzero_int_t("NATOMS")
        natoms_t.addParseAction(count, callDuringTry=True)

        return natoms_t + pre + expr + post

    cube_t = preamble_t(before_t, after_t)

    # parse the whole file and extract both all the values and the header
    with open(cube_path, "r") as cube_file:
        # we skip the first two lines as they are only comments and put the rest of the file in a single string
        cube_str = "".join(cube_file.readlines()[2:])  # The \n are already included in the string, don't need to double include them

    parsed_cube = cube_t.parseString(cube_str).asDict()
    # manually extracting voxel values
    if ("DSET_IDS" not in parsed_cube.keys()):
        parsed_cube["DSET_IDS"] = []

    cube_s = cube_str.split("\n")

    all_data_list = []

    # parse through a list of lines where the header has been removed, but the ORB_IDS remain, and append each value in a new all_data_list.
    for line in (cube_s[(4 + abs(parsed_cube["NATOMS"])):]):
        all_data_list.extend(line.split())

    if (len(parsed_cube["DSET_IDS"]) != 0):
        voxel_list = all_data_list[(len(parsed_cube["DSET_IDS"]) + 1):] # remove ORB_IDS from the all_data_list
    else:
        voxel_list = all_data_list

    parsed_cube["DATA"] = [float(value) for value in voxel_list]

    # start extracting the header values


    # get cube origin data
    N_atoms = parsed_cube["NATOMS"]
    origin = parsed_cube["ORIGIN"] if (world_unit == "bohr") else [p*ANGSTROM_2_BOHR for p in parsed_cube["ORIGIN"]]

    # Set the amount of values depending on if the DSET_IDs were present or not
    if (len(parsed_cube["DSET_IDS"]) != 0):
        N_vals = len(parsed_cube["DSET_IDS"])
    else:
        N_vals = parsed_cube["NVAL"][0]

    # files are given as [phi,rho,x,y]_[p,a,b]_[rsp,scf]_idx_#_[re,im].cube
    #TODO test that the file name makes sense
    path_ids = cube_path.split("/")[-1].split("_")[4]
    if ("-" in path_ids):
        from_to = path_ids.split("-")
        orb_ids = list(range(from_to[0], (from_to[1]+1), 1))  # we work as including the from and to, so 4-7 includes 4, 5, 6 and 7.
        if (N_vals != len(orb_ids)):
            raise ValueError("Different amount of orbitals in file and amount of orbitals specified in file name.")
    else:
        orb_ids = [float(path_ids)]


    # get voxel axis data to construct a basis for the cube space.
    N_steps = [parsed_cube["XAXIS"]["NVOXELS"], parsed_cube["YAXIS"]["NVOXELS"], parsed_cube["ZAXIS"]["NVOXELS"]]
    if (world_unit == "bohr"):
        Voxel_axes = [parsed_cube["XAXIS"]["VECTOR"], parsed_cube["YAXIS"]["VECTOR"], parsed_cube["ZAXIS"]["VECTOR"]]
    else:
        X_voxel = [p*ANGSTROM_2_BOHR for p in parsed_cube["XAXIS"]["VECTOR"]]
        Y_voxel = [p*ANGSTROM_2_BOHR for p in parsed_cube["YAXIS"]["VECTOR"]]
        Z_voxel = [p*ANGSTROM_2_BOHR for p in parsed_cube["ZAXIS"]["VECTOR"]]
        Voxel_axes = [X_voxel, Y_voxel, Z_voxel]

    # get the atom coordinates
    if (type(parsed_cube["GEOM"]) != list) :
        parsed_cube["GEOM"] = [parsed_cube["GEOM"]]

    Z_n = [atom["ATOMIC_NUMBER"] for atom in parsed_cube["GEOM"]]
    atom_charges = [atom["CHARGE"] for atom in parsed_cube["GEOM"]]
    atom_coords = [atom["POSITION"] if (world_unit == "bohr") else [p*ANGSTROM_2_BOHR for p in atom["POSITION"]] for atom in parsed_cube["GEOM"]]

    # construct the CUBE vector. Indexing is CUBE_vector[MO_ID][i*N_vals[1]*N_vals[2] + j*N_vals[2] + k] where i, j and k correspond to steps in the X, Y and Z voxel axes directions respectively.
    CUBE_vector = []
    for ID in range (N_vals):
        single_function = []
        for i in range(N_steps[0]):
            for j in range(N_steps[1]):
                for k in range(N_steps[2]):
                    single_function.append(parsed_cube["DATA"][i*N_steps[1]*N_steps[2]*N_vals + j*N_steps[2]*N_vals + k*N_vals + ID])
        CUBE_vector.append(single_function)

    cube_dict= {
            "CUBE_file": cube_path,
            "Header": {
                "N_atoms": N_atoms,
                "origin": origin,
                "N_steps": N_steps,
                "Voxel_axes": Voxel_axes,
                "Z_n": Z_n,
                "atom_charges": atom_charges,
                "atom_coords": atom_coords,
                "N_vals": N_vals
            },
            "ORB_IDS": orb_ids,
            "CUBE_data": CUBE_vector
    }
    return cube_dict
